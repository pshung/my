# Two principles 
1. write clear and specific prompt
2. give model more time to think

1.a. Use delimter to clear separate messages.  
1.b. Ask for a structured output such as jason.  
1.c. Ask the model to check whether conditions in the promot are satisfied  
1.d. "Few-shot" prompting (give a few successful examples) 

2.a. Specify the steps required to complete a task  
2.b. Ask for output in a specified format  
2.c. Instruct the model to work out its own solution before rushing to a conclusion  

# model hallucination
Model might give statement that sounds plausible but incorrect actually.  
how to avoid it?  Use the tactic above, ask model to find relevant information on its own and compare with your information.  


# LLM capability
1. summarize/extract information.  
2. inferring  (sentiment positive/negative)  
3. transforming  
